{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a difference between the annual income of default and full paid loans?\n",
    "- Is the difference statistically significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import probplot\n",
    "from scipy.stats.mstats import zscore\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "import nltk\n",
    "import collections as co\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read loans.csv as a dataframe\n",
    "loans_df = pd.read_csv('\n",
    "                       ',low_memory=False, engine='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
       "       'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
       "       'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose',\n",
       "       'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq',\n",
       "       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'initial_list_status', 'out_prncp',\n",
       "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
       "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
       "       'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt',\n",
       "       'next_pymnt_d', 'last_credit_pull_d', 'collections_12_mths_ex_med',\n",
       "       'mths_since_last_major_derog', 'policy_code', 'application_type',\n",
       "       'annual_inc_joint', 'dti_joint', 'verification_status_joint',\n",
       "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
       "       'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
       "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
       "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl',\n",
       "       'inq_last_12m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to classify loan status into one of the following bins ('Fully Paid', 'Default', 'Current')\n",
    "def loan_status_bin(text):\n",
    "    if text in ('Fully Paid', 'Does not meet the credit policy. Status:Fully Paid'):\n",
    "        return 'Fully Paid'\n",
    "    elif text in ('Current', 'Issued'):\n",
    "        return 'Current'\n",
    "    elif text in ('Charged Off', 'Default', 'Does not meet the credit policy. Status:Charged Off'):\n",
    "        return 'Default'\n",
    "    elif text in ('Late (16-30 days)', 'Late (31-120 days)', 'In Grace Period'):\n",
    "        return 'Late'\n",
    "    else:\n",
    "        'UNKNOWN BIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fully Paid', 'Default', 'Current', 'Late'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new attribute 'loan_status_bin' in the dataframe\n",
    "loans_df['loan_status_bin']=loans_df['loan_status'].apply(loan_status_bin)\n",
    "loans_df['loan_status_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df.fillna(loans_df.median()['annual_inc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df[loans_df['annual_inc'].isnull()==True]['annual_inc'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df_fp=loans_df[loans_df['loan_status_bin']=='Fully Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df_def=loans_df[loans_df['loan_status_bin']=='Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Default loans, mean annual income is 65199.76680867284, standard deviation is 56955.15545104668, size of dataframe is 47228\n"
     ]
    }
   ],
   "source": [
    "print('For Default loans, mean annual income is {0}, standard deviation is {1}, size of dataframe is {2}'.format(loans_df_def['annual_inc'].mean(), loans_df_def['annual_inc'].std(), len(loans_df_def['annual_inc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fully Paid loans, mean annual income is 74142.5024192341, standard deviation is 59205.29202398379, size of dataframe is 209711\n"
     ]
    }
   ],
   "source": [
    "print('For Fully Paid loans, mean annual income is {0}, standard deviation is {1}, size of dataframe is {2}'.format(loans_df_fp['annual_inc'].mean(), loans_df_fp['annual_inc'].std(), len(loans_df_fp['annual_inc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_mean=loans_df_def['annual_inc'].mean()\n",
    "def_std=loans_df_def['annual_inc'].std()\n",
    "\n",
    "fp_mean=loans_df_fp['annual_inc'].mean()\n",
    "fp_std=loans_df_fp['annual_inc'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8942.7356105612562, 292.23360521799054)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0_mean = 0\n",
    "mean_diff = abs(def_mean-fp_mean)\n",
    "sigma_diff = np.sqrt((fp_std**2)/len(loans_df_fp) + (def_std**2)/len(loans_df_def))\n",
    "mean_diff, sigma_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.601325278420518"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (mean_diff - h0_mean) / sigma_diff\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (1-stats.norm.cdf(z))*2\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to convert grade into numerical values\n",
    "def credit_grade(grade):\n",
    "    if grade in ('A'):\n",
    "        return 1\n",
    "    elif grade in ('B'):\n",
    "        return 2\n",
    "    elif grade in ('C'):\n",
    "        return 3\n",
    "    elif grade in ('D'):\n",
    "        return 4\n",
    "    elif grade in ('E'):\n",
    "        return 5\n",
    "    elif grade in ('F'):\n",
    "        return 6\n",
    "    elif grade in ('G'):\n",
    "        return 7\n",
    "    else:\n",
    "        99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 5, 6, 4, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new attribute 'loan_status_bin' in the dataframe\n",
    "loans_df['credit_grade']=loans_df['grade'].apply(credit_grade)\n",
    "loans_df['credit_grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INDIVIDUAL', 'JOINT'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df['application_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derived_income(x, y, z):\n",
    "    if x == 'INDIVIDUAL':\n",
    "        return y\n",
    "    elif x == 'JOINT':\n",
    "        return z\n",
    "    else:\n",
    "        0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df['derived_income']=loans_df.apply(lambda x: derived_income(x['application_type'], x['annual_inc'], x['annual_inc_joint']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derived_dti(x, y, z):\n",
    "    if x == 'INDIVIDUAL':\n",
    "        return y\n",
    "    elif x == 'JOINT':\n",
    "        return z\n",
    "    else:\n",
    "        0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df['derived_dti']=loans_df.apply(lambda x: derived_dti(x['application_type'], x['dti'], x['dti_joint']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df['inst_inc_ratio']=loans_df['installment']/ (loans_df['derived_income'] /12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: \n",
    "* loan_amount\n",
    "* credit_grade \n",
    "* interest_rate \n",
    "* derived_inc\n",
    "* derived_dti \n",
    "* inst_inc_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Datasets\n",
    "\n",
    "When fitting models, we would like to ensure two things:\n",
    "\n",
    "* We have found the best model (in terms of model parameters).\n",
    "* The model is highly likely to generalize i.e. perform well on unseen data.\n",
    "\n",
    "<br/>\n",
    "<div class=\"span5 alert alert-success\">\n",
    "<h4>Purpose of splitting data into Training/testing sets</h4>\n",
    "<ul>\n",
    "  <li> We built our model with the requirement that the model fit the data well. </li>\n",
    "  <li> As a side-effect, the model will fit <b>THIS</b> dataset well. What about new data? </li>\n",
    "    <ul>\n",
    "      <li> We wanted the model for predictions, right?</li>\n",
    "    </ul>\n",
    "  <li> One simple solution, leave out some data (for <b>testing</b>) and <b>train</b> the model on the rest </li>\n",
    "  <li> This also leads directly to the idea of cross-validation, next section. </li>  \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "First, we try a basic Logistic Regression:\n",
    "\n",
    "* Split the data into a training and test (hold-out) set\n",
    "* Train on the training set, and test for accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686339561405\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(loans_df[['loan_amnt', 'credit_grade', 'int_rate', 'derived_income', 'derived_dti', 'inst_inc_ratio']].values,\n",
    "                                              (loans_df.loan_status_bin).values,\n",
    "                                              random_state=5)\n",
    "##Xlr, Xtestlr, ylr, ytestlr = train_test_split(dflog[['Height','Weight']].values, (dflog.Gender == \"Male\").values, random_state=5)\n",
    " \n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Model\n",
    "\n",
    "The model has some hyperparameters we can tune for hopefully better performance. For tuning the parameters of your model, you will use a mix of *cross-validation* and *grid search*. In Logistic Regression, the most important parameter to tune is the *regularization parameter* `C`. Note that the regularization parameter is not always part of the logistic regression model. \n",
    "\n",
    "The regularization parameter is used to control for unlikely high regression coefficients, and in other cases can be used when data is sparse, as a method of feature selection.\n",
    "\n",
    "You will now implement some code to perform model tuning and selecting the regularization parameter $C$.\n",
    "\n",
    "We use the following `cv_score` function to perform K-fold cross-validation and apply a scoring function to each test fold. In this incarnation we use accuracy score as the default scoring function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of using the `cv_score` function for a basic logistic regression model without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688176711924\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "score = cv_score(clf1, Xlr, ylr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set II</h3>\n",
    "\n",
    "<b>Exercise:</b> Implement the following search procedure to find a good model\n",
    "<ul>\n",
    "<li> You are given a list of possible values of `C` below\n",
    "<li> For each C:\n",
    "  <ol>\n",
    "  <li> Create a logistic regression model with that value of C\n",
    "  <li> Find the average score for this model using the `cv_score` function **only on the training set** `(Xlr, ylr)`\n",
    "  </ol>\n",
    "<li> Pick the C with the highest average score\n",
    "</ul>\n",
    "Your goal is to find the best model parameters based *only* on the training set, without showing the model test set at all (which is why the test set is also called a *hold-out* set).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score:  0.688224793543 best_C:  10\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "max_score=0\n",
    "\n",
    "for C in Cs:\n",
    "    clf2 = LogisticRegression(C=C)\n",
    "    score = cv_score(clf2, Xlr, ylr)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        best_C =C\n",
    "print ('max_score: ',max_score, 'best_C: ', best_C)\n",
    "\n",
    "# your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set III</h3>\n",
    "**Exercise:** Now you want to estimate how this model will predict on unseen data in the following way:\n",
    "<ol>\n",
    "<li> Use the C you obtained from the procedure earlier and train a Logistic Regression on the training data\n",
    "<li> Calculate the accuracy on the test data\n",
    "</ol>\n",
    "\n",
    "<p>You may notice that this particular value of `C` may or may not do as well as simply running the default model on a random train-test split. </p>\n",
    "\n",
    "<ul>\n",
    "<li> Do you think that's a problem? \n",
    "<li> Why do we need to do this whole cross-validation and grid search stuff anyway?\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.68632603845 \n",
      "\n",
      "I don't think there is a problem, since model accuracy has increased with addition of a regularization parameter\n",
      "We perform cross-validation and grid search to tune hyperparameters of our model\n"
     ]
    }
   ],
   "source": [
    "clf3=LogisticRegression(C=best_C)\n",
    "clf3.fit(Xlr, ylr)\n",
    "ypred=clf3.predict(Xtestlr)\n",
    "print('accuracy score: ', accuracy_score(ypred, ytestlr), '\\n')\n",
    "print('I don\\'t think there is a problem, since model accuracy has '\n",
    "      'increased with addition of a regularization parameter')\n",
    "print('We perform cross-validation and grid search to tune hyperparameters of our model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Box Grid Search in `sklearn`\n",
    "\n",
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set IV</h3>\n",
    "\n",
    "<b>Exercise:</b> Use scikit-learn's [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) tool to perform cross validation and grid search. \n",
    "\n",
    "* Instead of writing your own loops above to iterate over the model parameters, can you use GridSearchCV to find the best model over the training set? \n",
    "* Does it give you the same best value of `C`?\n",
    "* How does this model you've obtained perform on the test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.686339561405 \n",
      "\n",
      "No, the new value of the C is:  0.0001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your turn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf4=LogisticRegression()\n",
    "parameters = {\"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "fitmodel = GridSearchCV(clf4, param_grid=parameters, cv=5, scoring=\"accuracy\", return_train_score=True)\n",
    "fitmodel.fit(Xlr, ylr)\n",
    "fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_, fitmodel.cv_results_\n",
    "\n",
    "clf5=LogisticRegression(C=fitmodel.best_params_['C'])\n",
    "clf5.fit(Xlr, ylr)\n",
    "ypred=clf5.predict(Xtestlr)\n",
    "\n",
    "print('accuracy score: ', accuracy_score(ypred, ytestlr), '\\n')\n",
    "print('No, the new value of the C is: ', fitmodel.best_params_['C'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(loans_df[['loan_amnt', 'credit_grade', 'int_rate', 'derived_income', 'derived_dti', 'inst_inc_ratio']].values,\n",
    "                                              (loans_df.loan_status_bin).values,\n",
    "                                              random_state=5)\n",
    " \n",
    "clf6 = svm.SVC()\n",
    "# Fit the model on the trainng data.\n",
    "clf6.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf6.predict(Xtestlr), ytestlr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
